{"title":"Lasso Regression","markdown":{"yaml":{"title":"Lasso Regression","editor_options":{"chunk_output_type":"console"}},"headingText":"Setting Up the Environment","containsRefs":false,"markdown":"\n\n\nLasso regression is a statistical model that combines linear/logistic regression with L1 regularization to perform both variable selection and regularization. The term \"Lasso\" stands for \"Least Absolute Shrinkage and Selection Operator.\" This method is particularly useful when dealing with datasets that have many predictors, as it helps to:\n- Reduce overfitting by penalizing large coefficients\n- Perform automatic feature selection by shrinking some coefficients to exactly zero\n- Handle multicollinearity by selecting only one variable from a group of highly correlated predictors\n\nIn this analysis, we'll use Lasso regression to predict weapon carrying behavior in schools, demonstrating how this method can help identify the most important predictors while maintaining model interpretability.\n\n\nFirst, we need to load the necessary packages for our analysis. We'll use `tidymodels` for modeling, `tidyverse` for data manipulation, and `here` for consistent file paths.\n\n```{r}\n#| label: packages\n#| output: false\n\nlibrary(here)\nlibrary(tidymodels)\nlibrary(tidyverse)\n```\n\n## Loading the Data\n\nWe'll work with pre-processed data sets that have been split into training and test sets, along with cross-validation folds. These files are stored in the `processed_data` directory.\n\n```{r}\n#| label: load-data\n\nanalysis_data <- readRDS(here(\"models\", \"data\", \"analysis_data.rds\"))\nanalysis_train <- readRDS(here(\"models\", \"data\", \"analysis_train.rds\"))\nanalysis_test <- readRDS(here(\"models\",\"data\", \"analysis_test.rds\"))\nanalysis_folds <- readRDS(here(\"models\", \"data\", \"analysis_folds.rds\"))\n```\n\n## Data Preprocessing\n\nBefore fitting our model, we need to preprocess the data. We'll create a recipe that:\n- Imputes missing values in categorical variables using the mode\n- Imputes missing values in numeric variables using the mean\n- Removes predictors with zero variance\n- Removes highly correlated predictors (correlation threshold = 0.7)\n- Creates dummy variables for categorical predictors\n\n```{r}\n#| label: model-rec\n\nweapon_carry_recipe <- \n  recipe(formula = WeaponCarryingSchool ~ ., data = analysis_train) |>\n  step_impute_mode(all_nominal_predictors()) |>\n  step_impute_mean(all_numeric_predictors()) |>\n  step_zv(all_predictors()) |> \n  step_corr(all_numeric_predictors(), threshold = 0.7) %>% \n  step_dummy(all_nominal_predictors())\n\nweapon_carry_recipe\n```\n\nLet's apply our recipe to transform the data according to these preprocessing steps.\n\n```{r}\nweapon_carry_recipe %>% \n  prep() %>% \n  bake(new_data = analysis_data) \n```\n\n## Model Specification\n\nWe'll use a logistic regression model with Lasso regularization. The Lasso (Least Absolute Shrinkage and Selection Operator) helps with feature selection by penalizing the absolute size of coefficients. We set `mixture = 1` to specify a pure Lasso model, and we'll tune the penalty parameter to find the optimal level of regularization.\n\n```{r}\n#| label: model-spec\n\nweapon_carry_spec <-\n  logistic_reg(penalty = tune(), \n               mixture = 1) |> \n  set_engine('glmnet')\n\nweapon_carry_spec\n```\n\n## Creating the Workflow\n\nWe'll combine our recipe and model specification into a single workflow. This ensures that all preprocessing steps are properly applied during both training and prediction.\n\n```{r}\n#| label: model-workflow\n\nweapon_carry_workflow <-\n  workflow() |>\n  add_recipe(weapon_carry_recipe) |>\n  add_model(weapon_carry_spec)\n\nweapon_carry_workflow\n```\n\n## Model Tuning\n\nTo find the optimal penalty value, we'll create a grid of potential values to test. We'll use 50 different penalty values, evenly spaced on a logarithmic scale.\n\n```{r}\nlambda_grid <- grid_regular(penalty(), levels = 50)\nlambda_grid\n```\n\nNow, we'll perform cross-validation to find the best penalty value. This process is time-consuming, so we'll save the results for future use.\n\n```{r}\n#| eval: false\n\nset.seed(2023)\n\nlasso_tune <- \n  tune_grid(\n  object = weapon_carry_workflow, \n  resamples = analysis_folds,\n  grid = lambda_grid, \n  control = control_resamples(event_level = \"second\")\n)\n```\n\n```{r}\n#| eval: false\n#| echo: false\n\nsaveRDS(lasso_tune, here(\"model_outputs\", \"lasso_tune.rds\"))\n```\n\n```{r}\n#| echo: false\n\nlasso_tune <- readRDS(here(\"models\", \"model_outputs\", \"lasso_tune.rds\"))\n```\n\nLet's examine the performance metrics for different penalty values.\n\n```{r}\nlasso_tune %>% \n  collect_metrics()\n```\n\nWe can visualize how the model's performance changes with different penalty values.\n\n```{r}\nautoplot(lasso_tune)\n```\n\n## Selecting the Best Model\n\nWe'll select the best model based on the ROC AUC metric, which measures the model's ability to distinguish between classes.\n\n```{r}\nbest <- lasso_tune |> \n  select_best(metric =\"roc_auc\")\n\nbest\n```\n\nNow we'll create our final workflow with the best penalty value.\n\n```{r}\nfinal_wf <- finalize_workflow(weapon_carry_workflow, best)\n\nfinal_wf\n```\n\n## Fitting the Final Model\n\nWe'll fit our final model on the training data. This process is also time-consuming, so we'll save the results.\n\n```{r}\n#| eval: false\n\nweapon_fit <- \n  fit(final_wf, data = analysis_train)\n\nweapon_fit\n```\n\n```{r}\n#| eval: false\n#| echo: false\n\nsaveRDS(weapon_fit, here(\"model_outputs\", \"weapon_fit.rds\"))\n```\n\n```{r}\n#| echo: false\n\nweapon_fit <- readRDS(here(\"models\",\"model_outputs\", \"weapon_fit.rds\"))\n```\n\n## Model Evaluation\n\nLet's examine the model's predictions on the training data.\n\n```{r}\nweapon_pred <- \n  augment(weapon_fit, analysis_train) |> \n  select(WeaponCarryingSchool, .pred_class, .pred_1, .pred_0)\n\nweapon_pred\n```\n\nWe can visualize the model's performance using an ROC curve.\n\n```{r}\nroc_plot_training <- \n  weapon_pred |> \n  roc_curve(truth = WeaponCarryingSchool, .pred_1, event_level = \"second\") |> \n  autoplot()\n\nroc_plot_training \n```\n\nLet's look at the model coefficients to understand which predictors are most important.\n\n```{r}\nweapon_fit |> \n  extract_fit_parsnip() |> \n  tidy()\n```\n\n## Cross-Validation Results\n\nWe'll fit the model on each cross-validation fold to get a more robust estimate of its performance.\n\n```{r}\n#| eval: false\n\nweapon_fit_resamples <- \n  fit_resamples(final_wf, resamples = analysis_folds)\n\nweapon_fit_resamples\n```\n\n```{r}\n#| eval: false\n#| echo: false\n\nsaveRDS(weapon_fit_resamples, here(\"model_outputs\", \"weapon_fit_resamples.rds\"))\n```\n\n```{r}\n#| echo: false\nweapon_fit_resamples <- readRDS(here(\"models\",\"model_outputs\", \"weapon_fit_resamples.rds\"))\n```\n\nLet's examine the cross-validation metrics.\n\n```{r}\ncollect_metrics(weapon_fit_resamples)\n```\n\n## Variable Importance\n\nFinally, let's create a variable importance plot to identify the most influential predictors in our model.\n\n```{r}\nlibrary(vip)\n\nweapon_fit |> \n  extract_fit_engine() |> \n  vip() \n```\n\n## Results and Interpretation\n\n[Add your interpretation of the results here]\n\n","srcMarkdownNoYaml":"\n\n\nLasso regression is a statistical model that combines linear/logistic regression with L1 regularization to perform both variable selection and regularization. The term \"Lasso\" stands for \"Least Absolute Shrinkage and Selection Operator.\" This method is particularly useful when dealing with datasets that have many predictors, as it helps to:\n- Reduce overfitting by penalizing large coefficients\n- Perform automatic feature selection by shrinking some coefficients to exactly zero\n- Handle multicollinearity by selecting only one variable from a group of highly correlated predictors\n\nIn this analysis, we'll use Lasso regression to predict weapon carrying behavior in schools, demonstrating how this method can help identify the most important predictors while maintaining model interpretability.\n\n## Setting Up the Environment\n\nFirst, we need to load the necessary packages for our analysis. We'll use `tidymodels` for modeling, `tidyverse` for data manipulation, and `here` for consistent file paths.\n\n```{r}\n#| label: packages\n#| output: false\n\nlibrary(here)\nlibrary(tidymodels)\nlibrary(tidyverse)\n```\n\n## Loading the Data\n\nWe'll work with pre-processed data sets that have been split into training and test sets, along with cross-validation folds. These files are stored in the `processed_data` directory.\n\n```{r}\n#| label: load-data\n\nanalysis_data <- readRDS(here(\"models\", \"data\", \"analysis_data.rds\"))\nanalysis_train <- readRDS(here(\"models\", \"data\", \"analysis_train.rds\"))\nanalysis_test <- readRDS(here(\"models\",\"data\", \"analysis_test.rds\"))\nanalysis_folds <- readRDS(here(\"models\", \"data\", \"analysis_folds.rds\"))\n```\n\n## Data Preprocessing\n\nBefore fitting our model, we need to preprocess the data. We'll create a recipe that:\n- Imputes missing values in categorical variables using the mode\n- Imputes missing values in numeric variables using the mean\n- Removes predictors with zero variance\n- Removes highly correlated predictors (correlation threshold = 0.7)\n- Creates dummy variables for categorical predictors\n\n```{r}\n#| label: model-rec\n\nweapon_carry_recipe <- \n  recipe(formula = WeaponCarryingSchool ~ ., data = analysis_train) |>\n  step_impute_mode(all_nominal_predictors()) |>\n  step_impute_mean(all_numeric_predictors()) |>\n  step_zv(all_predictors()) |> \n  step_corr(all_numeric_predictors(), threshold = 0.7) %>% \n  step_dummy(all_nominal_predictors())\n\nweapon_carry_recipe\n```\n\nLet's apply our recipe to transform the data according to these preprocessing steps.\n\n```{r}\nweapon_carry_recipe %>% \n  prep() %>% \n  bake(new_data = analysis_data) \n```\n\n## Model Specification\n\nWe'll use a logistic regression model with Lasso regularization. The Lasso (Least Absolute Shrinkage and Selection Operator) helps with feature selection by penalizing the absolute size of coefficients. We set `mixture = 1` to specify a pure Lasso model, and we'll tune the penalty parameter to find the optimal level of regularization.\n\n```{r}\n#| label: model-spec\n\nweapon_carry_spec <-\n  logistic_reg(penalty = tune(), \n               mixture = 1) |> \n  set_engine('glmnet')\n\nweapon_carry_spec\n```\n\n## Creating the Workflow\n\nWe'll combine our recipe and model specification into a single workflow. This ensures that all preprocessing steps are properly applied during both training and prediction.\n\n```{r}\n#| label: model-workflow\n\nweapon_carry_workflow <-\n  workflow() |>\n  add_recipe(weapon_carry_recipe) |>\n  add_model(weapon_carry_spec)\n\nweapon_carry_workflow\n```\n\n## Model Tuning\n\nTo find the optimal penalty value, we'll create a grid of potential values to test. We'll use 50 different penalty values, evenly spaced on a logarithmic scale.\n\n```{r}\nlambda_grid <- grid_regular(penalty(), levels = 50)\nlambda_grid\n```\n\nNow, we'll perform cross-validation to find the best penalty value. This process is time-consuming, so we'll save the results for future use.\n\n```{r}\n#| eval: false\n\nset.seed(2023)\n\nlasso_tune <- \n  tune_grid(\n  object = weapon_carry_workflow, \n  resamples = analysis_folds,\n  grid = lambda_grid, \n  control = control_resamples(event_level = \"second\")\n)\n```\n\n```{r}\n#| eval: false\n#| echo: false\n\nsaveRDS(lasso_tune, here(\"model_outputs\", \"lasso_tune.rds\"))\n```\n\n```{r}\n#| echo: false\n\nlasso_tune <- readRDS(here(\"models\", \"model_outputs\", \"lasso_tune.rds\"))\n```\n\nLet's examine the performance metrics for different penalty values.\n\n```{r}\nlasso_tune %>% \n  collect_metrics()\n```\n\nWe can visualize how the model's performance changes with different penalty values.\n\n```{r}\nautoplot(lasso_tune)\n```\n\n## Selecting the Best Model\n\nWe'll select the best model based on the ROC AUC metric, which measures the model's ability to distinguish between classes.\n\n```{r}\nbest <- lasso_tune |> \n  select_best(metric =\"roc_auc\")\n\nbest\n```\n\nNow we'll create our final workflow with the best penalty value.\n\n```{r}\nfinal_wf <- finalize_workflow(weapon_carry_workflow, best)\n\nfinal_wf\n```\n\n## Fitting the Final Model\n\nWe'll fit our final model on the training data. This process is also time-consuming, so we'll save the results.\n\n```{r}\n#| eval: false\n\nweapon_fit <- \n  fit(final_wf, data = analysis_train)\n\nweapon_fit\n```\n\n```{r}\n#| eval: false\n#| echo: false\n\nsaveRDS(weapon_fit, here(\"model_outputs\", \"weapon_fit.rds\"))\n```\n\n```{r}\n#| echo: false\n\nweapon_fit <- readRDS(here(\"models\",\"model_outputs\", \"weapon_fit.rds\"))\n```\n\n## Model Evaluation\n\nLet's examine the model's predictions on the training data.\n\n```{r}\nweapon_pred <- \n  augment(weapon_fit, analysis_train) |> \n  select(WeaponCarryingSchool, .pred_class, .pred_1, .pred_0)\n\nweapon_pred\n```\n\nWe can visualize the model's performance using an ROC curve.\n\n```{r}\nroc_plot_training <- \n  weapon_pred |> \n  roc_curve(truth = WeaponCarryingSchool, .pred_1, event_level = \"second\") |> \n  autoplot()\n\nroc_plot_training \n```\n\nLet's look at the model coefficients to understand which predictors are most important.\n\n```{r}\nweapon_fit |> \n  extract_fit_parsnip() |> \n  tidy()\n```\n\n## Cross-Validation Results\n\nWe'll fit the model on each cross-validation fold to get a more robust estimate of its performance.\n\n```{r}\n#| eval: false\n\nweapon_fit_resamples <- \n  fit_resamples(final_wf, resamples = analysis_folds)\n\nweapon_fit_resamples\n```\n\n```{r}\n#| eval: false\n#| echo: false\n\nsaveRDS(weapon_fit_resamples, here(\"model_outputs\", \"weapon_fit_resamples.rds\"))\n```\n\n```{r}\n#| echo: false\nweapon_fit_resamples <- readRDS(here(\"models\",\"model_outputs\", \"weapon_fit_resamples.rds\"))\n```\n\nLet's examine the cross-validation metrics.\n\n```{r}\ncollect_metrics(weapon_fit_resamples)\n```\n\n## Variable Importance\n\nFinally, let's create a variable importance plot to identify the most influential predictors in our model.\n\n```{r}\nlibrary(vip)\n\nweapon_fit |> \n  extract_fit_engine() |> \n  vip() \n```\n\n## Results and Interpretation\n\n[Add your interpretation of the results here]\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../styles.css"],"toc":true,"output-file":"lasso.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.7.29","theme":"flatly","title":"Lasso Regression","editor_options":{"chunk_output_type":"console"}},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}