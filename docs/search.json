[
  {
    "objectID": "models/logistic.html",
    "href": "models/logistic.html",
    "title": "Logistic Regression",
    "section": "",
    "text": "Logistic regression is a statistical model that…\n\nModel Overview\nLogistic regression is used when the dependent variable is binary (0/1, Yes/No, True/False). The model estimates the probability of the dependent variable being 1 given the independent variables.\n\n\nImplementation\n\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(dissertationData)\nlibrary(here)\n\n# Load and prepare the YRBS 2023 dataset\n\n\n\nLoad the data\n\nanalysis_data &lt;- readRDS(here(\"models\", \"data\", \"analysis_data.rds\"))\nanalysis_train &lt;- readRDS(here(\"models\", \"data\", \"analysis_train.rds\"))\nanalysis_test &lt;- readRDS(here(\"models\", \"data\", \"analysis_test.rds\"))\nanalysis_folds &lt;- readRDS(here(\"models\", \"data\", \"analysis_folds.rds\"))\n\n\n\nRecipe\n\nweapon_carry_recipe &lt;- \n  recipe(formula = WeaponCarryingSchool ~ ., data = analysis_data) |&gt;\n  step_impute_mode(all_nominal_predictors()) |&gt;\n  step_impute_mean(all_numeric_predictors()) |&gt;\n  step_zv(all_predictors()) |&gt; \n  step_corr(all_numeric_predictors(), threshold = 0.7) \n\nweapon_carry_recipe\n\n\n\n\n── Recipe ──────────────────────────────────────────────────────────────────────\n\n\n\n\n\n── Inputs \n\n\nNumber of variables by role\n\n\noutcome:    1\npredictor: 10\n\n\n\n\n\n── Operations \n\n\n• Mode imputation for: all_nominal_predictors()\n\n\n• Mean imputation for: all_numeric_predictors()\n\n\n• Zero variance filter on: all_predictors()\n\n\n• Correlation filter on: all_numeric_predictors()\n\n\n\n\nBake\n\nrec &lt;- weapon_carry_recipe %&gt;% \n  prep() %&gt;% \n  bake(new_data = analysis_data) %&gt;% glimpse()\n\nRows: 19,595\nColumns: 11\n$ AttackedInNeighborhood   &lt;fct&gt; 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, …\n$ Bullying                 &lt;fct&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ SexualAbuseByOlderPerson &lt;fct&gt; 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, …\n$ ParentalPhysicalAbuse    &lt;fct&gt; 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ ParentSubstanceUse       &lt;fct&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, …\n$ ParentIncarceration      &lt;fct&gt; 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ SchoolConnectedness      &lt;fct&gt; 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, …\n$ ParentalMonitoring       &lt;fct&gt; 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, …\n$ UnfairDisciplineAtSchool &lt;fct&gt; 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ Homelessness             &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ WeaponCarryingSchool     &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n\n\n\n\nModel Specification\n\nweapon_carry_spec &lt;- \n  logistic_reg() %&gt;% \n  set_mode(\"classification\") %&gt;% \n  set_engine(\"glm\") \n\nweapon_carry_spec\n\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm \n\n\n\n\nWorkflow\n\nweapon_carry_workflow &lt;- workflow() %&gt;%\n  add_recipe(weapon_carry_recipe) %&gt;%\n  add_model(weapon_carry_spec)\n\n\nweapon_carry_workflow\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n4 Recipe Steps\n\n• step_impute_mode()\n• step_impute_mean()\n• step_zv()\n• step_corr()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm \n\n\n\nmod_1 &lt;- \n  fit(weapon_carry_workflow, data = analysis_train) \n\nmod_1\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n4 Recipe Steps\n\n• step_impute_mode()\n• step_impute_mean()\n• step_zv()\n• step_corr()\n\n── Model ───────────────────────────────────────────────────────────────────────\n\nCall:  stats::glm(formula = ..y ~ ., family = stats::binomial, data = data)\n\nCoefficients:\n              (Intercept)    AttackedInNeighborhood1  \n                 -3.29938                    0.74950  \n                Bullying1  SexualAbuseByOlderPerson1  \n                  0.48405                    0.46540  \n   ParentalPhysicalAbuse1        ParentSubstanceUse1  \n                  0.71713                   -0.15917  \n     ParentIncarceration1       SchoolConnectedness1  \n                  0.07048                   -0.25542  \n      ParentalMonitoring1  UnfairDisciplineAtSchool1  \n                  0.59860                   -0.24268  \n            Homelessness1  \n                  1.18053  \n\nDegrees of Freedom: 14695 Total (i.e. Null);  14685 Residual\nNull Deviance:      5238 \nResidual Deviance: 4872     AIC: 4894\n\n\n\ntidy_model &lt;- \n  mod_1 |&gt;\n  tidy(exponentiate = TRUE,\n       conf.int = TRUE, \n       conf.level = .95) |&gt;\n  mutate(p.value = scales::pvalue(p.value))\n\ntidy_model\n\n# A tibble: 11 × 7\n   term                  estimate std.error statistic p.value conf.low conf.high\n   &lt;chr&gt;                    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt;\n 1 (Intercept)             0.0369    0.166    -19.9   &lt;0.001    0.0266    0.0508\n 2 AttackedInNeighborho…   2.12      0.0954     7.85  &lt;0.001    1.75      2.55  \n 3 Bullying1               1.62      0.0919     5.27  &lt;0.001    1.35      1.94  \n 4 SexualAbuseByOlderPe…   1.59      0.133      3.51  &lt;0.001    1.22      2.06  \n 5 ParentalPhysicalAbus…   2.05      0.179      4.01  &lt;0.001    1.43      2.89  \n 6 ParentSubstanceUse1     0.853     0.111     -1.44  0.151     0.688     1.06  \n 7 ParentIncarceration1    1.07      0.126      0.560 0.575     0.841     1.38  \n 8 SchoolConnectedness1    0.775     0.0970    -2.63  0.008     0.639     0.935 \n 9 ParentalMonitoring1     1.82      0.114      5.26  &lt;0.001    1.45      2.27  \n10 UnfairDisciplineAtSc…   0.785     0.114     -2.13  0.033     0.629     0.984 \n11 Homelessness1           3.26      0.155      7.61  &lt;0.001    2.39      4.39  \n\n\n\n\nModel Evaluation\n\n# Evaluate the model\n# [Add your model evaluation code here]\n\n\n\nResults and Interpretation\n\n\nVisualizations\n\n# Add your visualizations here\n\n\n\nKey Takeaways\n\n\nReferences"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Machine Learning Notebook 👀",
    "section": "",
    "text": "This website will be our Machine Learning course, where we explore various statistical and machine learning models using the Youth Risk Behavior Survey (YRBS) 2023 dataset. Through this course, I learned to implement and understand different modeling techniques using the tidymodels framework in R.\n\nWhat You’ll Find Here\n\nAbout Me: A little bit about me and my research interests.\nThe Dataset: Information about my primary dataset and the research question I am trying to answer.\nModel Implementations: Hands-on examples of different models to answer the question:\n\nLogistic Regression\nLasso Regression\nDecision Trees\nRandom Forest\nK-Nearest Neighbors (KNN)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "I am Catalina Canizares\nI am a researcher dedicated to preventing suicidal behaviors in adolescents. Currently, I am a postdoctoral researcher at NYU Steinhardt School of Culture, Education, and Human Development. My work spans several projects, including intervention programs for preventing suicide attempts and developing data structures to deepen our understanding of adolescent suicide attempts and ideation.\nI am deeply invested in data science, applying machine learning techniques to reveal insights and patterns in suicide-related data. As a primary user of R, I am committed to sharing my knowledge and experiences with the broader community.\nI am also dedicated to ensuring clarity and reproducibility in my work, using tools like Quarto and RMarkdown. This approach ensures that my research is trustworthy and easily followed by others.\nIf I could describe myself using three emojis I would select: 🏝🇨🇴🐈"
  },
  {
    "objectID": "models/datasets.html",
    "href": "models/datasets.html",
    "title": "Data and Research Question",
    "section": "",
    "text": "The Youth Risk Behavior Survey (YRBS) is a…\n\n\n\nSource: Centers for Disease Control and Prevention (CDC)\nYear: 2023\nTarget Population: High school students\nSample Size: [Add sample size]\n\n\n\n\nThe dataset includes information on various health-related behaviors:\n\nDemographic Variables\n\n…\n…\n…\n\nOutcome\n\n…\n…\n…\n…\n\nPredictors\n\n…\n…\n…\n…\n\n\n\n\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.3.0 ──\n✔ broom        1.0.8     ✔ rsample      1.3.0\n✔ dials        1.4.0     ✔ tune         1.3.0\n✔ infer        1.0.8     ✔ workflows    1.2.0\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.3.1     ✔ yardstick    1.3.2\n✔ recipes      1.3.1     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n\nlibrary(dissertationData)\nlibrary(here)\n\nhere() starts at /cloud/project\n\ndata(clean_yrbs_2023)\n# Add your data preprocessing code here\n\n\n\n\n\n\n\n\n# This is an example of how to create a dataset for a model.\n# You can use this as a template to create your own dataset.\n\n\nanalysis_data &lt;- clean_yrbs_2023 %&gt;%\n    select(WeaponCarryingSchool, AttackedInNeighborhood, Bullying, \n           SexualAbuseByOlderPerson, ParentalPhysicalAbuse, ParentSubstanceUse, \n           ParentIncarceration, SchoolConnectedness, ParentalMonitoring, \n           UnfairDisciplineAtSchool, Homelessness) |&gt;\n    filter(!is.na(WeaponCarryingSchool)) %&gt;% \n    mutate(across(\n          c(ParentSubstanceUse, ParentIncarceration, SchoolConnectedness,\n            ParentalMonitoring, UnfairDisciplineAtSchool),\n          ~ as.numeric(.x) - 1\n          )) %&gt;% \n  mutate(across(\n    c(ParentSubstanceUse, ParentIncarceration, SchoolConnectedness,\n      ParentalMonitoring, UnfairDisciplineAtSchool),\n    ~ factor(.x)\n  ))\n\n\n\n\n\n\n\n\nanalysis_folds &lt;- vfold_cv(analysis_train,\n    v = 5\n)\nanalysis_folds"
  },
  {
    "objectID": "models/datasets.html#youth-risk-behavior-survey-2023",
    "href": "models/datasets.html#youth-risk-behavior-survey-2023",
    "title": "Data and Research Question",
    "section": "",
    "text": "The Youth Risk Behavior Survey (YRBS) is a…\n\n\n\nSource: Centers for Disease Control and Prevention (CDC)\nYear: 2023\nTarget Population: High school students\nSample Size: [Add sample size]\n\n\n\n\nThe dataset includes information on various health-related behaviors:\n\nDemographic Variables\n\n…\n…\n…\n\nOutcome\n\n…\n…\n…\n…\n\nPredictors\n\n…\n…\n…\n…\n\n\n\n\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.3.0 ──\n✔ broom        1.0.8     ✔ rsample      1.3.0\n✔ dials        1.4.0     ✔ tune         1.3.0\n✔ infer        1.0.8     ✔ workflows    1.2.0\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.3.1     ✔ yardstick    1.3.2\n✔ recipes      1.3.1     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n\nlibrary(dissertationData)\nlibrary(here)\n\nhere() starts at /cloud/project\n\ndata(clean_yrbs_2023)\n# Add your data preprocessing code here\n\n\n\n\n\n\n\n\n# This is an example of how to create a dataset for a model.\n# You can use this as a template to create your own dataset.\n\n\nanalysis_data &lt;- clean_yrbs_2023 %&gt;%\n    select(WeaponCarryingSchool, AttackedInNeighborhood, Bullying, \n           SexualAbuseByOlderPerson, ParentalPhysicalAbuse, ParentSubstanceUse, \n           ParentIncarceration, SchoolConnectedness, ParentalMonitoring, \n           UnfairDisciplineAtSchool, Homelessness) |&gt;\n    filter(!is.na(WeaponCarryingSchool)) %&gt;% \n    mutate(across(\n          c(ParentSubstanceUse, ParentIncarceration, SchoolConnectedness,\n            ParentalMonitoring, UnfairDisciplineAtSchool),\n          ~ as.numeric(.x) - 1\n          )) %&gt;% \n  mutate(across(\n    c(ParentSubstanceUse, ParentIncarceration, SchoolConnectedness,\n      ParentalMonitoring, UnfairDisciplineAtSchool),\n    ~ factor(.x)\n  ))\n\n\n\n\n\n\n\n\nanalysis_folds &lt;- vfold_cv(analysis_train,\n    v = 5\n)\nanalysis_folds"
  },
  {
    "objectID": "models/lasso.html",
    "href": "models/lasso.html",
    "title": "Lasso Regression",
    "section": "",
    "text": "Lasso regression is a statistical model that combines linear/logistic regression with L1 regularization to perform both variable selection and regularization. The term “Lasso” stands for “Least Absolute Shrinkage and Selection Operator.” This method is particularly useful when dealing with datasets that have many predictors, as it helps to: - Reduce overfitting by penalizing large coefficients - Perform automatic feature selection by shrinking some coefficients to exactly zero - Handle multicollinearity by selecting only one variable from a group of highly correlated predictors\nIn this analysis, we’ll use Lasso regression to predict weapon carrying behavior in schools, demonstrating how this method can help identify the most important predictors while maintaining model interpretability."
  },
  {
    "objectID": "models/lasso.html#setting-up-the-environment",
    "href": "models/lasso.html#setting-up-the-environment",
    "title": "Lasso Regression",
    "section": "Setting Up the Environment",
    "text": "Setting Up the Environment\nFirst, we need to load the necessary packages for our analysis. We’ll use tidymodels for modeling, tidyverse for data manipulation, and here for consistent file paths.\n\nlibrary(here)\nlibrary(tidymodels)\nlibrary(tidyverse)"
  },
  {
    "objectID": "models/lasso.html#loading-the-data",
    "href": "models/lasso.html#loading-the-data",
    "title": "Lasso Regression",
    "section": "Loading the Data",
    "text": "Loading the Data\nWe’ll work with pre-processed data sets that have been split into training and test sets, along with cross-validation folds. These files are stored in the processed_data directory.\n\nanalysis_data &lt;- readRDS(here(\"models\", \"data\", \"analysis_data.rds\"))\nanalysis_train &lt;- readRDS(here(\"models\", \"data\", \"analysis_train.rds\"))\nanalysis_test &lt;- readRDS(here(\"models\",\"data\", \"analysis_test.rds\"))\nanalysis_folds &lt;- readRDS(here(\"models\", \"data\", \"analysis_folds.rds\"))"
  },
  {
    "objectID": "models/lasso.html#data-preprocessing",
    "href": "models/lasso.html#data-preprocessing",
    "title": "Lasso Regression",
    "section": "Data Preprocessing",
    "text": "Data Preprocessing\nBefore fitting our model, we need to preprocess the data. We’ll create a recipe that: - Imputes missing values in categorical variables using the mode - Imputes missing values in numeric variables using the mean - Removes predictors with zero variance - Removes highly correlated predictors (correlation threshold = 0.7) - Creates dummy variables for categorical predictors\n\nweapon_carry_recipe &lt;- \n  recipe(formula = WeaponCarryingSchool ~ ., data = analysis_train) |&gt;\n  step_impute_mode(all_nominal_predictors()) |&gt;\n  step_impute_mean(all_numeric_predictors()) |&gt;\n  step_zv(all_predictors()) |&gt; \n  step_corr(all_numeric_predictors(), threshold = 0.7) %&gt;% \n  step_dummy(all_nominal_predictors())\n\nweapon_carry_recipe\n\n\n\n\n── Recipe ──────────────────────────────────────────────────────────────────────\n\n\n\n\n\n── Inputs \n\n\nNumber of variables by role\n\n\noutcome:    1\npredictor: 10\n\n\n\n\n\n── Operations \n\n\n• Mode imputation for: all_nominal_predictors()\n\n\n• Mean imputation for: all_numeric_predictors()\n\n\n• Zero variance filter on: all_predictors()\n\n\n• Correlation filter on: all_numeric_predictors()\n\n\n• Dummy variables from: all_nominal_predictors()\n\n\nLet’s apply our recipe to transform the data according to these preprocessing steps.\n\nweapon_carry_recipe %&gt;% \n  prep() %&gt;% \n  bake(new_data = analysis_data) \n\n# A tibble: 19,595 × 11\n   WeaponCarryingSchool AttackedInNeighborhood_X1 Bullying_X1\n   &lt;fct&gt;                                    &lt;dbl&gt;       &lt;dbl&gt;\n 1 0                                            0           0\n 2 0                                            0           1\n 3 0                                            0           0\n 4 0                                            0           0\n 5 0                                            0           0\n 6 0                                            1           0\n 7 0                                            0           0\n 8 0                                            0           0\n 9 0                                            0           0\n10 0                                            0           0\n# ℹ 19,585 more rows\n# ℹ 8 more variables: SexualAbuseByOlderPerson_X1 &lt;dbl&gt;,\n#   ParentalPhysicalAbuse_X1 &lt;dbl&gt;, ParentSubstanceUse_X1 &lt;dbl&gt;,\n#   ParentIncarceration_X1 &lt;dbl&gt;, SchoolConnectedness_X1 &lt;dbl&gt;,\n#   ParentalMonitoring_X1 &lt;dbl&gt;, UnfairDisciplineAtSchool_X1 &lt;dbl&gt;,\n#   Homelessness_X1 &lt;dbl&gt;"
  },
  {
    "objectID": "models/lasso.html#model-specification",
    "href": "models/lasso.html#model-specification",
    "title": "Lasso Regression",
    "section": "Model Specification",
    "text": "Model Specification\nWe’ll use a logistic regression model with Lasso regularization. The Lasso (Least Absolute Shrinkage and Selection Operator) helps with feature selection by penalizing the absolute size of coefficients. We set mixture = 1 to specify a pure Lasso model, and we’ll tune the penalty parameter to find the optimal level of regularization.\n\nweapon_carry_spec &lt;-\n  logistic_reg(penalty = tune(), \n               mixture = 1) |&gt; \n  set_engine('glmnet')\n\nweapon_carry_spec\n\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nComputational engine: glmnet"
  },
  {
    "objectID": "models/lasso.html#creating-the-workflow",
    "href": "models/lasso.html#creating-the-workflow",
    "title": "Lasso Regression",
    "section": "Creating the Workflow",
    "text": "Creating the Workflow\nWe’ll combine our recipe and model specification into a single workflow. This ensures that all preprocessing steps are properly applied during both training and prediction.\n\nweapon_carry_workflow &lt;-\n  workflow() |&gt;\n  add_recipe(weapon_carry_recipe) |&gt;\n  add_model(weapon_carry_spec)\n\nweapon_carry_workflow\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_mode()\n• step_impute_mean()\n• step_zv()\n• step_corr()\n• step_dummy()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nComputational engine: glmnet"
  },
  {
    "objectID": "models/lasso.html#model-tuning",
    "href": "models/lasso.html#model-tuning",
    "title": "Lasso Regression",
    "section": "Model Tuning",
    "text": "Model Tuning\nTo find the optimal penalty value, we’ll create a grid of potential values to test. We’ll use 50 different penalty values, evenly spaced on a logarithmic scale.\n\nlambda_grid &lt;- grid_regular(penalty(), levels = 50)\nlambda_grid\n\n# A tibble: 50 × 1\n    penalty\n      &lt;dbl&gt;\n 1 1   e-10\n 2 1.60e-10\n 3 2.56e-10\n 4 4.09e-10\n 5 6.55e-10\n 6 1.05e- 9\n 7 1.68e- 9\n 8 2.68e- 9\n 9 4.29e- 9\n10 6.87e- 9\n# ℹ 40 more rows\n\n\nNow, we’ll perform cross-validation to find the best penalty value. This process is time-consuming, so we’ll save the results for future use.\n\nset.seed(2023)\n\nlasso_tune &lt;- \n  tune_grid(\n  object = weapon_carry_workflow, \n  resamples = analysis_folds,\n  grid = lambda_grid, \n  control = control_resamples(event_level = \"second\")\n)\n\nLet’s examine the performance metrics for different penalty values.\n\nlasso_tune %&gt;% \n  collect_metrics()\n\n# A tibble: 150 × 7\n    penalty .metric     .estimator  mean     n std_err .config              \n      &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                \n 1 1   e-10 accuracy    binary     0.957     5 0.00158 Preprocessor1_Model01\n 2 1   e-10 brier_class binary     0.881     5 0.00160 Preprocessor1_Model01\n 3 1   e-10 roc_auc     binary     0.688     5 0.00742 Preprocessor1_Model01\n 4 1.60e-10 accuracy    binary     0.957     5 0.00158 Preprocessor1_Model02\n 5 1.60e-10 brier_class binary     0.881     5 0.00160 Preprocessor1_Model02\n 6 1.60e-10 roc_auc     binary     0.688     5 0.00742 Preprocessor1_Model02\n 7 2.56e-10 accuracy    binary     0.957     5 0.00158 Preprocessor1_Model03\n 8 2.56e-10 brier_class binary     0.881     5 0.00160 Preprocessor1_Model03\n 9 2.56e-10 roc_auc     binary     0.688     5 0.00742 Preprocessor1_Model03\n10 4.09e-10 accuracy    binary     0.957     5 0.00158 Preprocessor1_Model04\n# ℹ 140 more rows\n\n\nWe can visualize how the model’s performance changes with different penalty values.\n\nautoplot(lasso_tune)"
  },
  {
    "objectID": "models/lasso.html#selecting-the-best-model",
    "href": "models/lasso.html#selecting-the-best-model",
    "title": "Lasso Regression",
    "section": "Selecting the Best Model",
    "text": "Selecting the Best Model\nWe’ll select the best model based on the ROC AUC metric, which measures the model’s ability to distinguish between classes.\n\nbest &lt;- lasso_tune |&gt; \n  select_best(metric =\"roc_auc\")\n\nbest\n\n# A tibble: 1 × 2\n   penalty .config              \n     &lt;dbl&gt; &lt;chr&gt;                \n1 0.000339 Preprocessor1_Model33\n\n\nNow we’ll create our final workflow with the best penalty value.\n\nfinal_wf &lt;- finalize_workflow(weapon_carry_workflow, best)\n\nfinal_wf\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_mode()\n• step_impute_mean()\n• step_zv()\n• step_corr()\n• step_dummy()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = 0.000339322177189533\n  mixture = 1\n\nComputational engine: glmnet"
  },
  {
    "objectID": "models/lasso.html#fitting-the-final-model",
    "href": "models/lasso.html#fitting-the-final-model",
    "title": "Lasso Regression",
    "section": "Fitting the Final Model",
    "text": "Fitting the Final Model\nWe’ll fit our final model on the training data. This process is also time-consuming, so we’ll save the results.\n\nweapon_fit &lt;- \n  fit(final_wf, data = analysis_train)\n\nweapon_fit"
  },
  {
    "objectID": "models/lasso.html#model-evaluation",
    "href": "models/lasso.html#model-evaluation",
    "title": "Lasso Regression",
    "section": "Model Evaluation",
    "text": "Model Evaluation\nLet’s examine the model’s predictions on the training data.\n\nweapon_pred &lt;- \n  augment(weapon_fit, analysis_train) |&gt; \n  select(WeaponCarryingSchool, .pred_class, .pred_1, .pred_0)\n\nweapon_pred\n\n# A tibble: 14,696 × 4\n   WeaponCarryingSchool .pred_class .pred_1 .pred_0\n   &lt;fct&gt;                &lt;fct&gt;         &lt;dbl&gt;   &lt;dbl&gt;\n 1 0                    0            0.0368   0.963\n 2 0                    0            0.0410   0.959\n 3 0                    0            0.0253   0.975\n 4 0                    0            0.0325   0.968\n 5 0                    0            0.125    0.875\n 6 0                    0            0.0368   0.963\n 7 0                    0            0.0208   0.979\n 8 0                    0            0.0208   0.979\n 9 0                    0            0.0458   0.954\n10 0                    0            0.0529   0.947\n# ℹ 14,686 more rows\n\n\nWe can visualize the model’s performance using an ROC curve.\n\nroc_plot_training &lt;- \n  weapon_pred |&gt; \n  roc_curve(truth = WeaponCarryingSchool, .pred_1, event_level = \"second\") |&gt; \n  autoplot()\n\nroc_plot_training \n\n\n\n\n\n\n\n\nLet’s look at the model coefficients to understand which predictors are most important.\n\nweapon_fit |&gt; \n  extract_fit_parsnip() |&gt; \n  tidy()\n\n\nAttaching package: 'Matrix'\n\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\n\nLoaded glmnet 4.1-8\n\n\n# A tibble: 11 × 3\n   term                        estimate  penalty\n   &lt;chr&gt;                          &lt;dbl&gt;    &lt;dbl&gt;\n 1 (Intercept)                  -3.29   0.000339\n 2 AttackedInNeighborhood_X1     0.739  0.000339\n 3 Bullying_X1                   0.472  0.000339\n 4 SexualAbuseByOlderPerson_X1   0.455  0.000339\n 5 ParentalPhysicalAbuse_X1      0.708  0.000339\n 6 ParentSubstanceUse_X1        -0.132  0.000339\n 7 ParentIncarceration_X1        0.0271 0.000339\n 8 SchoolConnectedness_X1       -0.226  0.000339\n 9 ParentalMonitoring_X1         0.584  0.000339\n10 UnfairDisciplineAtSchool_X1  -0.229  0.000339\n11 Homelessness_X1               1.17   0.000339"
  },
  {
    "objectID": "models/lasso.html#cross-validation-results",
    "href": "models/lasso.html#cross-validation-results",
    "title": "Lasso Regression",
    "section": "Cross-Validation Results",
    "text": "Cross-Validation Results\nWe’ll fit the model on each cross-validation fold to get a more robust estimate of its performance.\n\nweapon_fit_resamples &lt;- \n  fit_resamples(final_wf, resamples = analysis_folds)\n\nweapon_fit_resamples\n\nLet’s examine the cross-validation metrics.\n\ncollect_metrics(weapon_fit_resamples)\n\n# A tibble: 3 × 6\n  .metric     .estimator   mean     n std_err .config             \n  &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy    binary     0.957      5 0.00158 Preprocessor1_Model1\n2 brier_class binary     0.0399     5 0.00128 Preprocessor1_Model1\n3 roc_auc     binary     0.688      5 0.00737 Preprocessor1_Model1"
  },
  {
    "objectID": "models/lasso.html#variable-importance",
    "href": "models/lasso.html#variable-importance",
    "title": "Lasso Regression",
    "section": "Variable Importance",
    "text": "Variable Importance\nFinally, let’s create a variable importance plot to identify the most influential predictors in our model.\n\nlibrary(vip)\n\n\nAttaching package: 'vip'\n\n\nThe following object is masked from 'package:utils':\n\n    vi\n\nweapon_fit |&gt; \n  extract_fit_engine() |&gt; \n  vip()"
  },
  {
    "objectID": "models/lasso.html#results-and-interpretation",
    "href": "models/lasso.html#results-and-interpretation",
    "title": "Lasso Regression",
    "section": "Results and Interpretation",
    "text": "Results and Interpretation\n[Add your interpretation of the results here]"
  }
]